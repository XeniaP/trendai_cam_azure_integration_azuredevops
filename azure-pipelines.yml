trigger:
- main

variables:
  AZURE_SERVICE_CONNECTION: 'AutomationCAM'
  SELF_HOSTED_POOL_NAME: 'CAMAutomation' # Optional
  MAX_PARALLEL: 3
  TF_VERSION: '1.14.1'
  #MAIN_REGION: 'eastus'

stages:
- stage: deploy
  displayName: Deploy in parallel per subscription
  jobs:

  - job: build_matrix
    workspace:
      clean: all
    displayName: Build matrix from Azure subscriptions
    pool:
      name: $(SELF_HOSTED_POOL_NAME)
      #vmImage: ubuntu-latest
    steps:
    - checkout: self
    - bash: |
        set -euo pipefail
        python3 - <<'PY'
        import json
        subs = json.load(open("subscriptions/subs.json"))
        matrix = {}
        for s in subs:
          key = (
              s["name"]
              .replace(" ", "_")
              .replace("/", "_")
              .replace("(", "")
              .replace(")", "")
          )
          matrix[key] = {
              "SUB_NAME": s["name"],
              "SUB_ID": s["id"],
              "BACKEND_URL": s["backend_url"],
              "STORAGE_ACCOUNT": s["storage_account"],
              "MAIN_REGION": s["main_region"]
          }
        print("##vso[task.setvariable variable=MATRIX;isOutput=true]" + json.dumps(matrix))
        PY
      name: setMatrix
      displayName: "Create matrix output variable"

    - publish: subscriptions/subs.json
      artifact: subs_json
      displayName: "Publish subs.json (debug)"

  - job: run_per_subscription
    displayName: Run per subscription (parallel)
    dependsOn: build_matrix
    pool:
      name: $(SELF_HOSTED_POOL_NAME)
      #vmImage: ubuntu-latest
    workspace:
      clean: all
    strategy:
      matrix: $[ dependencies.build_matrix.outputs['setMatrix.MATRIX'] ]
      maxParallel: ${{ variables.MAX_PARALLEL }}

    steps:
    - checkout: self

    - bash: |
        #!/usr/bin/env bash
        set -euo pipefail
        export DEBIAN_FRONTEND=noninteractive

        # Base deps
        sudo apt-get update -y
        sudo apt-get install -y --no-install-recommends ca-certificates curl unzip jq python3 python3-venv python3-pip
        # --- Install Azure CLI in a dedicated venv (no apt repo Microsoft) ---
        if ! command -v az >/dev/null 2>&1; then
          sudo rm -rf /var/lib/apt/lists/* && sudo apt-get update && sudo curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
        fi
        az --version | head -n 2
        az config set extension.use_dynamic_install=yes_without_prompt
      displayName: "Install Azure CLI"
    
    - bash: |
        #!/usr/bin/env bash
        set -euo pipefail
        rm -rf .terraform*
        if command -v terraform >/dev/null 2>&1; then
          CUR="$(terraform version | head -n1 | awk '{print $2}' | tr -d 'v')"
        else
          CUR=""
        fi
        if [[ "$CUR" != "$TF_VERSION" ]]; then
          echo "== Install Terraform ${TF_VERSION} =="
          TF_DIR="$(Agent.TempDirectory)/terraform"
          mkdir -p "$TF_DIR"
          curl -fsSLo /tmp/terraform.zip \
            "https://releases.hashicorp.com/terraform/${TF_VERSION}/terraform_${TF_VERSION}_linux_amd64.zip"
          unzip -o /tmp/terraform.zip -d "$TF_DIR"
          chmod +x "$TF_DIR/terraform"
          sudo ln -sf "$TF_DIR/terraform" /usr/local/bin/terraform && export PATH="$TF_DIR:$PATH"
          echo "##vso[task.prependpath]$TF_DIR"
        else
          echo "Terraform already at $TF_VERSION"
        fi
      displayName: "Install Terraform and dependencies"
    
    - task: AzureCLI@2
      displayName: "Check Quota and permissions"
      name: CheckQuota
      inputs:
        azureSubscription: $(AZURE_SERVICE_CONNECTION)
        scriptType: 'bash'
        scriptLocation: inlineScript
        addSpnToEnvironment: true
        inlineScript: |
          set -euo pipefail
          #!/bin/bash
          set -euo pipefail

          SUB_ID=$(SUB_ID)
          MAIN_REGION=$(MAIN_REGION)

          # Listas de regiones permitidas (como strings para comparaciones rápidas en Bash)
          ALLOWED_AVTD_LIST="southafricanorth australiaeast australiasoutheast centralindia eastasia japaneast japanwest koreacentral southindia southeastasia westindia canadacentral canadaeast francecentral germanywestcentral northeurope norwayeast swedencentral switzerlandnorth uksouth ukwest westeurope uaenorth brazilsouth centralus eastus eastus2 northcentralus southcentralus westus westus2 westus3"
          ALLOWED_DSPM_LIST="australiaeast centralindia japaneast southeastasia germanywestcentral uksouth uaenorth brazilsouth eastus"

          # --- Funciones de Cuota ---
          get_y1_limit() {
              local sub="$1" reg="$2"
              local out
              LIMIT=$(az rest --method get --url "https://management.azure.com/subscriptions/$sub/providers/Microsoft.Web/locations/$reg/usages?api-version=2024-11-01" --query "value[?contains(name.value,'Y1')].limit | [0]" -o tsv | tr -d '\r')
              CURRENT=$(az rest --method get --url "https://management.azure.com/subscriptions/$sub/providers/Microsoft.Web/locations/$reg/usages?api-version=2024-11-01" --query "value[?contains(name.value,'Y1')].currentValue | [0]" -o tsv | tr -d '\r')
              echo "=> $sub: The quota limit for Y1 in region $reg is: $LIMIT (current: $CURRENT)"
              [[ "$LIMIT" =~ ^[0-9]+$ ]] && echo "$LIMIT" || echo "0"
          }

          get_basv2_cores_limit() {
              local sub="$1" reg="$2"
              local out
              LIMIT=$(az quota quota --resource-name "standardBasv2Family" --scope "/subscriptions/$sub/providers/Microsoft.Compute/locations/$reg" --query "properties.limit.value" -o tsv | tr -d '\r')
              CURRENT=$(az quota quota --resource-name "standardBasv2Family" --scope "/subscriptions/$sub/providers/Microsoft.Compute/locations/$reg" --query "properties.currentValue.value" -o tsv | tr -d '\r')
              echo "=> $sub: The quota limit for standardBasv2Family cores in region $reg is: $LIMIT (current: $CURRENT)"
              [[ "$LIMIT" =~ ^[0-9]+$ ]] && echo "$LIMIT" || echo "0"
          }

          get_ep1_available() {
              local sub="$1" reg="$2"
              local out
              EP1_LIMIT=$(az rest --method get --url "https://management.azure.com/subscriptions/$sub/providers/Microsoft.Web/locations/$reg/usages?api-version=2024-11-01" --query "value[?contains(name.value,'EP1')].limit | [0]" -o tsv | tr -d '\r')
              EP1_CURRENT=$(az rest --method get --url "https://management.azure.com/subscriptions/$sub/providers/Microsoft.Web/locations/$reg/usages?api-version=2024-11-01" --query "value[?contains(name.value,'EP1')].currentValue | [0]" -o tsv | tr -d '\r')
              echo "=> $sub: The quota for EP1 in region $reg is: $EP1_CURRENT / $EP1_LIMIT"
          }

          # 1. Chequeo de EP1 en Región Principal
          EP1_AVAILABLE=$(az rest --method get --url "https://management.azure.com/subscriptions/$SUB_ID/providers/Microsoft.Web/locations/$MAIN_REGION/usages?api-version=2024-11-01" --query "value[?name.value=='EP1'] | [0] | currentValue < limit" -o tsv 2>/dev/null || echo "false")
          #FS_ENABLE=$([ "$EP1_AVAILABLE" == "true" ] && echo "true" || echo "false")
          FS_ENABLE="true"

          RAW_AVTD=$(az graph query -q "resources | where subscriptionId == '$SUB_ID' | where type in~ ('microsoft.compute/virtualmachines', 'microsoft.containerregistry/registries') | project location | distinct location" --query "data[].location" -o tsv | tr '[:upper:]' '[:lower:]')
          echo "Regins with AVTD-related resources: $RAW_AVTD"
          FINAL_AVTD_ARRAY=()
          for REG in $RAW_AVTD; do
              if [[ $ALLOWED_AVTD_LIST =~ (^|[[:space:]])$REG($|[[:space:]]) ]]; then
                FINAL_AVTD_ARRAY+=("$REG")
              fi
          done

          RAW_DSPM=$(az graph query -q "resources | where subscriptionId == '$SUB_ID' | where type =~ 'microsoft.compute/virtualmachines' or type =~ 'microsoft.storage/storageaccounts' | project location | distinct location" --query "data[].location" -o tsv | tr '[:upper:]' '[:lower:]')
          echo "Regins with DSPM-related resources: $RAW_DSPM"
          FINAL_DSPM_ARRAY=()
          for REG in $RAW_DSPM; do
              if [[ $ALLOWED_DSPM_LIST =~ (^|[[:space:]])$REG($|[[:space:]]) ]]; then
                FINAL_DSPM_ARRAY+=("$REG")
              fi
          done

          AVTD_JSON=$(printf '%s\n' "${FINAL_AVTD_ARRAY[@]:-}" | jq -R . | jq -s -c 'map(select(. != ""))')
          DSPM_JSON=$(printf '%s\n' "${FINAL_DSPM_ARRAY[@]:-}" | jq -R . | jq -s -c 'map(select(. != ""))')

          echo "Allowed AVTD regions: $ALLOWED_AVTD_LIST"
          echo "Allowed DSPM regions: $ALLOWED_DSPM_LIST"

          echo "AVTD: $AVTD_JSON"
          echo "DSPM: $DSPM_JSON"

          echo "##vso[task.setvariable variable=FS_ENABLE;isOutput=true]$FS_ENABLE"
          echo "##vso[task.setvariable variable=DEPLOY_AVTD_REGIONS;isOutput=true]$AVTD_JSON"
          echo "##vso[task.setvariable variable=DEPLOY_DSPM_REGIONS;isOutput=true]$DSPM_JSON"
      env:
        SUB_ID: $(SUB_ID)
        REGION: $(MAIN_REGION)

    - task: AzureCLI@2
      displayName: "Deploy Integration"
      inputs:
        azureSubscription: $(AZURE_SERVICE_CONNECTION)
        scriptType: 'bash'
        scriptLocation: inlineScript
        addSpnToEnvironment: true
        inlineScript: |
          set -euo pipefail
          
          # Capturamos los valores (que vienen como [reg1,reg2])
          RAW_AVTD=$(CheckQuota.DEPLOY_AVTD_REGIONS)
          RAW_DSPM=$(CheckQuota.DEPLOY_DSPM_REGIONS)

          # FUNCIÓN MÁGICA: Convierte el texto [a,b] en JSON real ["a","b"]
          to_clean_json() {
            local input="$1"
            echo "$input" | tr -d '[]' | tr ',' '\n' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//' | jq -R . | jq -s -c .
          }

          # Re-procesamos para asegurar que tengan comillas
          export AVTD_REGIONS=$(to_clean_json "$RAW_AVTD")
          export DSPM_REGIONS=$(to_clean_json "$RAW_DSPM")
          export FS_STATUS=$(CheckQuota.FS_ENABLE)

          echo "FS_STATUS: $FS_STATUS"
          echo "AVTD_REGIONS: $AVTD_REGIONS" # Ahora saldrá con ["..."]
          echo "DSPM_REGIONS: $DSPM_REGIONS"

          echo "== Setting TrendAI Environment =="
          export PKG_ZIP="cloud-account-management-terraform-package.zip"
          export PKG_DIR="cloud-account-management-terraform-package"

          rm -rf "$PKG_DIR"
          mkdir -p "$PKG_DIR"
          curl -fsSL \
            "$BACKEND_URL" \
            -o "$PKG_ZIP"
          
          unzip -o "$PKG_ZIP" -d "$PKG_DIR"

          function remove_feature_module_block() {
              local feature=$1
              echo "== Optimizing FEATURES list =="
              CURRENT_FEATURES=$(grep "export FEATURES=" "$PKG_DIR/deploy.sh" | cut -d"'" -f2)
              UPDATED_FEATURES=$(echo "$CURRENT_FEATURES" | jq -c 'map(select(. != "'"$feature"'"))')
              sed -i "s|export FEATURES=.*|export FEATURES='$UPDATED_FEATURES'|" "$PKG_DIR/deploy.sh"
          }

          echo "== Override Configuration according environment characteristics =="
          find "$PKG_DIR" -maxdepth 2 -type f -name "*.sh" -print
          chmod +x "$PKG_DIR"/*.sh || true
          chmod +x "$PKG_DIR"/cam/*.sh 2>/dev/null || true
          sed -i "s/export CAM_DEPLOYED_REGION=\".*\"/export CAM_DEPLOYED_REGION=\"${MAIN_REGION}\"/" "$PKG_DIR/deploy.sh" || true
          sed -i "s|^export SUBSCRIPTION_ID=.*|export SUBSCRIPTION_ID=\"${SUB_ID}\"|g" "$PKG_DIR/deploy.sh" || true
          sed -i "s|^export CLOUD_ACCOUNT_NAME=.*|export CLOUD_ACCOUNT_NAME=\"${CLOUD_ACCOUNT_NAME}\"|g" "$PKG_DIR/deploy.sh" || true
          sed -i "s|^export TF_AUTO_APPROVE=.*|export TF_AUTO_APPROVE=true|g" "$PKG_DIR/deploy.sh" || true
          sed -i 's/default *= *true/default = false/g' "$PKG_DIR/cam/variables.tf"
          remove_feature_module_block "azure-activity-log"

          echo "== Setting custom configuration for Data Security Posture Management =="
          VALID_DSPM_COUNT=$(echo "$DSPM_REGIONS" | jq '[.[] | select(. != "")] | length' 2>/dev/null || echo 0)
          if [[ -z "$DSPM_REGIONS" || "$VALID_DSPM_COUNT" -eq 0 ]]; then
            REGIONS_COUNT_DSPM=0
            sed -i 's/"data-security-posture-management": .*/"data-security-posture-management": [],/' "$PKG_DIR/deploy.sh"
            remove_feature_module_block "data-security-posture-management"
            DSPM_JSON="[]"
          else
            echo "DSPM will be deployed in the following regions: $DSPM_REGIONS"
            DSPM_JSON=$(echo "$DSPM_REGIONS" | jq -c .)
          fi

          echo "== Setting custom configuration for Agentless Vulnerability & Threat Detection =="
          VALID_AVTD_COUNT=$(echo "$AVTD_REGIONS" | jq '[.[] | select(. != "")] | length' 2>/dev/null || echo 0)
          if [[ -z "$AVTD_REGIONS" || "$VALID_AVTD_COUNT" -eq 0 ]]; then
              REGIONS_COUNT_AVTD=0
              sed -i 's/"cloud-sentry": .*/"cloud-sentry": [],/' "$PKG_DIR/deploy.sh"
              remove_feature_module_block "cloud-sentry"
              AVTD_JSON="[]"
          else
              echo "AVTD will be deployed in the following regions: $AVTD_REGIONS"
              AVTD_JSON=$(echo "$AVTD_REGIONS" | jq -c .)
          fi
          NEW_JSON_VALUE=$(jq -n -c \
            --argjson cs "$AVTD_JSON" \
            --argjson dspm "$DSPM_JSON" \
            '{
              "cloud-sentry": $cs,
              "data-security-posture-management": $dspm,
              "file-storage-security": null,
              "real-time-posture-monitoring": null
            }')
          echo "New FEATURES_DEPLOYED_REGIONS value: $NEW_JSON_VALUE"
          perl -i -0777 -pe "s/export FEATURES_DEPLOYED_REGIONS='\{.*?\}'/export FEATURES_DEPLOYED_REGIONS='$NEW_JSON_VALUE'/s" "$PKG_DIR/deploy.sh"

          echo "== Setting custom configuration for File Storage Security =="
          if [[ "$FS_STATUS" == "false" ]]; then
            echo "== File Storage Security will be disabled due to lack of EP1 quota in the main region =="
            remove_feature_module_block "file-storage-security"
            sed -i '/"file-storage-security"[[:space:]]*:[[:space:]]*null,/d' "$PKG_DIR/deploy.sh"
          else
            echo "== Additional Configuration for File Storage Security =="
            if [[ -n "${STORAGE_ACCOUNT:-}" ]]; then
              echo "Setting quarantine storage account to ${STORAGE_ACCOUNT}"
              sed -i "s|quarantine_storage_account *= *\"[^\"]*\"|quarantine_storage_account = \"${STORAGE_ACCOUNT}\"|g" "$PKG_DIR/main.tf" || true
            fi
          fi

          echo "== DEBUG DEPLOY.SH =="
          cat "$PKG_DIR/deploy.sh"  # Debug: Check deploy.sh content after modifications

          echo "== Setting the subscription context =="
          az account set --subscription "$SUB_ID"

          echo "== Setting authentication parameters =="
          export ARM_SUBSCRIPTION_ID="$SUB_ID"
          export ARM_TENANT_ID="$tenantId"
          export ARM_CLIENT_ID="$servicePrincipalId"
          if [[ -n "${servicePrincipalKey:-}" ]]; then
            echo "== Using SPN secret auth =="
            export ARM_CLIENT_SECRET="$servicePrincipalKey"
            unset ARM_USE_OIDC ARM_OIDC_TOKEN || true
          elif [[ -n "${idToken:-}" ]]; then
            echo "== Using OIDC auth (federated service connection) =="
            export ARM_USE_OIDC=true
            export ARM_OIDC_TOKEN="$idToken"
            unset ARM_CLIENT_SECRET || true
          else
            echo "ERROR: No servicePrincipalKey and no idToken. Check your Service Connection type." >&2
            exit 1
          fi

          echo "== Deploying with Terraform =="
          cd "$PKG_DIR"
          export TF_LOG=ERROR
          #./deploy.sh

          # 1. Definición de Prefijos y Variables
          SA_PREFIX="camtfstatestorage"
          CONTAINER_PREFIX="camtfstate"
          BLOB_NAME="terraform.tfstate"
          LOCAL_STATE="terraform.tfstate"
          DEPLOY_SH="deploy.sh"

          # 2. Definir el Universo Total de Features (Módulos)
          # Agrega aquí todos los nombres de módulos que existen en tu Terraform
          ALL_FEATURES=("cloud-sentry" "data-security-posture-management" "file-storage-security" "real-time-posture-monitoring" "azure-activity-log")

          echo "== Identificando Features Activas en deploy.sh =="
          ACTIVE_FEATURES_JSON=$(grep "export FEATURES=" "$DEPLOY_SH" | cut -d"'" -f2)
          echo "Features activas detectadas: $ACTIVE_FEATURES_JSON"
          STORAGE_ACCOUNT=$(az storage account list --query "[?starts_with(name, '$SA_PREFIX')].name | [0]" -o tsv | tr -d '\r')
          CONTAINER_NAME=$(az storage container list --account-name "$STORAGE_ACCOUNT" --query "[?starts_with(name, '$CONTAINER_PREFIX')].name | [0]" -o tsv | tr -d '\r')

          if [[ -z "$STORAGE_ACCOUNT" || -z "$CONTAINER_NAME" ]]; then
              echo "ERROR: No se encontró la infraestructura de estado."
              exit 1
          fi

          # 5. Descargar el Estado Actual
          az storage blob download --account-name "$STORAGE_ACCOUNT" --container-name "$CONTAINER_NAME" --name "$BLOB_NAME" --file "$LOCAL_STATE" --overwrite --no-progress

          # 6. Comparar y Eliminar Módulos Inactivos
          echo "== Sincronizando Estado con Features =="
          terraform init -backend=false

          for FEATURE in "${ALL_FEATURES[@]}"; do
              # Verificamos si la feature NO está en el JSON de activas
              IS_ACTIVE=$(echo "$ACTIVE_FEATURES_JSON" | jq -r ". | contains([\"$FEATURE\"])")
              
              if [ "$IS_ACTIVE" == "false" ]; then
                  echo "[INACTIVA] Removiendo módulo 'module.$FEATURE' del estado..."
                  # Intentamos remover tanto el nombre de la feature como el nombre técnico del módulo
                  terraform state rm "module.$FEATURE" 2>/dev/null || echo "Info: module.$FEATURE no estaba en el estado."
              else
                  echo "[ACTIVA] Manteniendo 'module.$FEATURE'."
              fi
          done

          # 7. Subir el Estado Limpio
          echo "== Actualizando Estado en Azure =="
          az storage blob upload --account-name "$STORAGE_ACCOUNT" --container-name "$CONTAINER_NAME" --name "$BLOB_NAME" --file "$LOCAL_STATE" --overwrite

          echo "Sincronización finalizada el $(date)."
          echo "Executing deployment script..."
          ./deploy.sh
      env:
        SUB_ID: $(SUB_ID)
        BACKEND_URL: $(BACKEND_URL)
        STORAGE_ACCOUNT: $(STORAGE_ACCOUNT)
        CLOUD_ACCOUNT_NAME: "$(SUB_NAME)"
        MAIN_REGION: $(MAIN_REGION)
